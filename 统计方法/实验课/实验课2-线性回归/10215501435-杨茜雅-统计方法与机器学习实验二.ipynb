{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbbb2998",
   "metadata": {},
   "source": [
    "##                                                  统计方法与机器学习实验二\n",
    "\n",
    "###                                                                                                                                                              10215501435 杨茜雅\n",
    "\n",
    "## 背景描述\n",
    "\n",
    "汽车发动机在测功机上产生的**制动马力**被认为是**发动机转速**(每分钟转数，rpm)、**燃料的道路辛烷值**和**发动机压缩值**的函数，我们在实验室里进行实验，研究它们的函数关系。\n",
    "\n",
    "## 数据描述\n",
    "| 变量名 | 变量含义 | 变量类型 | 变量取值范围 |\n",
    "| :----------: | :--------: | :----------: | :----------: |\n",
    "| rpm | 发动机转速 | 连续变量 | $R^+$ |\n",
    "| Road_Octane_Number | 道路辛烷值 | 连续变量 | $R+$ |\n",
    "| Compression | 压缩值 | 连续变量 | $R^+$ |\n",
    "| Brake_Horsepower | 制动马力 | 连续变量 | $R^+$ |\n",
    "\n",
    "## 任务 \n",
    "注：这里使用 $\\alpha=0.05$ 的显著性水平。\n",
    "\n",
    "1. 请用多元线性回归模型，描述制动马力和发动机转速、道路辛烷值以及压缩值之间的函数关系。\n",
    "2. 分别将数据中心化、标准化之后，比较参数估计的异同，并进行评述（提示：可以结合理论课的课件）。\n",
    "3. 从模型显著性、参数显著性以及残差分析三个角度，分析多元线性回归模型是否合理。\n",
    "4. 若取发动机转速为3000转/min，道路辛烷值为90，发动机压缩值为100时，分别给出制动马力值的置信区间和预测区间。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "80232deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # 修改工作目录\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from jupyterquiz import display_quiz\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from scipy.stats import f\n",
    "from scipy.stats import t\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "946e1836",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/86138/统计方法实验二/Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52638002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data 3 is shown as follows: \n",
      "      rpm  Road Octane Number  Compression  Brake Horsepower\n",
      "0   2000                  90          100               225\n",
      "1   1800                  94           95               212\n",
      "2   2400                  88          110               229\n",
      "3   1900                  91           96               222\n",
      "4   1600                  86          100               219\n",
      "5   2500                  96          110               278\n",
      "6   3000                  94           98               246\n",
      "7   3200                  90          100               237\n",
      "8   2800                  88          105               233\n",
      "9   3400                  86           97               224\n",
      "10  1800                  90          100               223\n",
      "11  2500                  89          104               230\n"
     ]
    }
   ],
   "source": [
    "print('Data 3 is shown as follows: \\n', pd.read_csv(\"Project_3.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a8b6cbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    rpm  Road Octane Number  Compression  Brake Horsepower\n",
      "0  2000                  90          100               225\n",
      "1  1800                  94           95               212\n",
      "2  2400                  88          110               229\n",
      "3  1900                  91           96               222\n",
      "4  1600                  86          100               219\n"
     ]
    }
   ],
   "source": [
    "Data = pd.read_csv(\"Project_3.csv\")\n",
    "print(Data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "20f72805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of instances is  12\n",
      "The number of features is  3\n"
     ]
    }
   ],
   "source": [
    "n = Data.shape[0]\n",
    "p = Data.shape[1] - 1\n",
    "print(\"The number of instances is \", n)\n",
    "print(\"The number of features is \", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c45990",
   "metadata": {},
   "source": [
    "# Task 1: 请用多元线性回归模型，描述制动马力和发动机转速、道路辛烷值以及压缩值之间的函数关系。\n",
    "\n",
    "多元线性回归模型形如\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1 x_{1} + \\beta_2 x_{2} + \\beta_3 x_{3} + \\epsilon_{i}, i=1,2,\\cdots,n\n",
    "$$\n",
    "其中，$\\beta_0,\\beta_1,\\beta_2,\\beta_3$分别是未知参数，而$\\epsilon_{i}$是误差项，且满足$E(\\epsilon_{i}) = 0$和$Var(\\epsilon_{i}) = \\sigma^2$。$n$表示样本量。\n",
    "\n",
    "我们可以用矩阵的形式来写这个模型，即\n",
    "$$\n",
    "\\mathbf{y} = \\mathbf{X}\\mathbf{\\beta} + \\mathbf{\\epsilon}\n",
    "$$\n",
    "其中，\n",
    "- 响应变量构成的向量为$$\n",
    "\\mathbf{y} = \\begin{pmatrix}y_1\\\\y_2\\\\\\vdots\\\\ y_n\\end{pmatrix},\n",
    "$$\n",
    "- 自变量/特征构成的矩阵$$\n",
    "\\mathbf{X} = \\begin{pmatrix}\n",
    "1 & x_{11} & x_{12} \\\\\n",
    "1 & x_{21} & x_{22} \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "1 & x_{n1} & x_{n2} \\\\\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "- 待估参数向量为\n",
    "$$\n",
    "\\mathbf{\\beta} = \\begin{pmatrix}\n",
    "\\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "- 误差向量为\n",
    "$$\n",
    "\\mathbf{\\epsilon} = \\begin{pmatrix}\\epsilon_1\\\\\\epsilon_2\\\\\\vdots\\\\ \\epsilon_n\\end{pmatrix}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d441f8",
   "metadata": {},
   "source": [
    "已知参数向量的估计为\n",
    "$$\n",
    "\\hat{\\mathbf{\\beta}} = (\\mathbf{X}'\\mathbf{X})^{-1} \\mathbf{X}'\\mathbf{y}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223bfeae",
   "metadata": {},
   "source": [
    "**Solution:**  \n",
    "使用多元线性回归的方法，令发动机转速为$X_1$，道路辛烷值为$X_2$，压缩值为$X_3$，制动马力为$Y$。则线性模型为：$Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\beta_3X_3 +\\epsilon$，并假定随机误差项符合正态分布。根据以上数据，可以求得$\\hat{\\beta_1},\\hat{\\beta_2},\\hat{\\beta_3}$及线性回归方程如下。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b37d4e",
   "metadata": {},
   "source": [
    "## 课上代码迁移 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a79cca85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimates of the parameters are \n",
      " [-2.660312e+02  1.070000e-02  3.134800e+00  1.867400e+00]\n"
     ]
    }
   ],
   "source": [
    "## Method 1: Matrix Calculus\n",
    "Data1 = sm.add_constant(Data)\n",
    "Data1_value = Data1.values\n",
    "X = Data1_value[:,0:(p+1)]\n",
    "y = Data1_value[:,-1]\n",
    "beta_hat_1 = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
    "# A @ B <=> np.dot(A,B) matrix multiply\n",
    "print(\"The estimates of the parameters are \\n\", \n",
    "      np.around(beta_hat_1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6405fa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    rpm  Road_Octane_Number  Compression  Brake_Horsepower\n",
      "0  2000                  90          100               225\n",
      "1  1800                  94           95               212\n",
      "2  2400                  88          110               229\n",
      "3  1900                  91           96               222\n",
      "4  1600                  86          100               219\n",
      "The estimates of the parameters are \n",
      " Intercept            -266.0312\n",
      "rpm                     0.0107\n",
      "Road_Octane_Number      3.1348\n",
      "Compression             1.8674\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Method 2: 「statsmodels」 package\n",
    "Data2 = pd.read_csv(\"Project_3.csv\")\n",
    "\n",
    "# 将列名中的空格改为下划线\n",
    "Data2 = Data2.rename(columns={'Road Octane Number': 'Road_Octane_Number', 'Brake Horsepower': 'Brake_Horsepower'})\n",
    "\n",
    "# 打印前几行数据，检查列名是否已更改\n",
    "print(Data2.head())\n",
    "\n",
    "model1 = ols(\"Brake_Horsepower ~ rpm + Road_Octane_Number + Compression\", Data2).fit()\n",
    "beta_hat_2 = model1.params\n",
    "#print(\"The estimates of the parameters are \\n\", \n",
    "#      round(model.param(),4))\n",
    "print(\"The estimates of the parameters are \\n\", \n",
    "      round(beta_hat_2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "081a0ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimates of the parameters are \n",
      " [-2.660312e+02  1.070000e-02  3.134800e+00  1.867400e+00]\n"
     ]
    }
   ],
   "source": [
    "## Method 3: 「scikit-learn」package\n",
    "model2 = linear_model.LinearRegression()\n",
    "X_without_intercept = X[:,1:4]\n",
    "model2.fit(X_without_intercept, y)\n",
    "beta_hat_3 = np.append(np.array(model2.intercept_),model2.coef_)\n",
    "print(\"The estimates of the parameters are \\n\", \n",
    "      np.around(beta_hat_3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85b786a",
   "metadata": {},
   "source": [
    "## 自己尝试 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f63f3547",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    intercept      P1    P2     P3      F\n",
      "0         1.0  2000.0  90.0  100.0  225.0\n",
      "1         1.0  1800.0  94.0   95.0  212.0\n",
      "2         1.0  2400.0  88.0  110.0  229.0\n",
      "3         1.0  1900.0  91.0   96.0  222.0\n",
      "4         1.0  1600.0  86.0  100.0  219.0\n",
      "5         1.0  2500.0  96.0  110.0  278.0\n",
      "6         1.0  3000.0  94.0   98.0  246.0\n",
      "7         1.0  3200.0  90.0  100.0  237.0\n",
      "8         1.0  2800.0  88.0  105.0  233.0\n",
      "9         1.0  3400.0  86.0   97.0  224.0\n",
      "10        1.0  1800.0  90.0  100.0  223.0\n",
      "11        1.0  2500.0  89.0  104.0  230.0\n",
      "参数估计值: \n",
      " Intercept   -266.0312\n",
      "P1             0.0107\n",
      "P2             3.1348\n",
      "P3             1.8674\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>F</td>        <th>  R-squared:         </th> <td>   0.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 07 Oct 2023</td> <th>  Prob (F-statistic):</th>  <td>0.00317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:22:12</td>     <th>  Log-Likelihood:    </th> <td> -40.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    12</td>      <th>  AIC:               </th> <td>   89.42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     8</td>      <th>  BIC:               </th> <td>   91.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> -266.0312</td> <td>   92.674</td> <td>   -2.871</td> <td> 0.021</td> <td> -479.737</td> <td>  -52.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P1</th>        <td>    0.0107</td> <td>    0.004</td> <td>    2.390</td> <td> 0.044</td> <td>    0.000</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P2</th>        <td>    3.1348</td> <td>    0.844</td> <td>    3.712</td> <td> 0.006</td> <td>    1.188</td> <td>    5.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P3</th>        <td>    1.8674</td> <td>    0.535</td> <td>    3.494</td> <td> 0.008</td> <td>    0.635</td> <td>    3.100</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.392</td> <th>  Durbin-Watson:     </th> <td>   1.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.822</td> <th>  Jarque-Bera (JB):  </th> <td>   0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.282</td> <th>  Prob(JB):          </th> <td>   0.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.625</td> <th>  Cond. No.          </th> <td>9.03e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.03e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        F         & \\textbf{  R-squared:         } &     0.807   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.734   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     11.12   \\\\\n",
       "\\textbf{Date:}             & Sat, 07 Oct 2023 & \\textbf{  Prob (F-statistic):} &  0.00317    \\\\\n",
       "\\textbf{Time:}             &     15:22:12     & \\textbf{  Log-Likelihood:    } &   -40.708   \\\\\n",
       "\\textbf{No. Observations:} &          12      & \\textbf{  AIC:               } &     89.42   \\\\\n",
       "\\textbf{Df Residuals:}     &           8      & \\textbf{  BIC:               } &     91.36   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &    -266.0312  &       92.674     &    -2.871  &         0.021        &     -479.737    &      -52.325     \\\\\n",
       "\\textbf{P1}        &       0.0107  &        0.004     &     2.390  &         0.044        &        0.000    &        0.021     \\\\\n",
       "\\textbf{P2}        &       3.1348  &        0.844     &     3.712  &         0.006        &        1.188    &        5.082     \\\\\n",
       "\\textbf{P3}        &       1.8674  &        0.535     &     3.494  &         0.008        &        0.635    &        3.100     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.392 & \\textbf{  Durbin-Watson:     } &    1.043  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.822 & \\textbf{  Jarque-Bera (JB):  } &    0.230  \\\\\n",
       "\\textbf{Skew:}          & -0.282 & \\textbf{  Prob(JB):          } &    0.891  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.625 & \\textbf{  Cond. No.          } & 9.03e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 9.03e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      F   R-squared:                       0.807\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     11.12\n",
       "Date:                Sat, 07 Oct 2023   Prob (F-statistic):            0.00317\n",
       "Time:                        15:22:12   Log-Likelihood:                -40.708\n",
       "No. Observations:                  12   AIC:                             89.42\n",
       "Df Residuals:                       8   BIC:                             91.36\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   -266.0312     92.674     -2.871      0.021    -479.737     -52.325\n",
       "P1             0.0107      0.004      2.390      0.044       0.000       0.021\n",
       "P2             3.1348      0.844      3.712      0.006       1.188       5.082\n",
       "P3             1.8674      0.535      3.494      0.008       0.635       3.100\n",
       "==============================================================================\n",
       "Omnibus:                        0.392   Durbin-Watson:                   1.043\n",
       "Prob(Omnibus):                  0.822   Jarque-Bera (JB):                0.230\n",
       "Skew:                          -0.282   Prob(JB):                        0.891\n",
       "Kurtosis:                       2.625   Cond. No.                     9.03e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.03e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "x = pd.read_csv('Project_3.csv')\n",
    "x.insert(0, 'intercept', np.ones(len(x))) \n",
    "data = x.values * 1\n",
    "df = pd.DataFrame(data, columns = ['intercept', 'P1', 'P2', 'P3', 'F'])\n",
    "print(df)\n",
    "\n",
    "# Do the multiple linear regression\n",
    "model = ols('F ~ P1 + P2 + P3', df).fit()\n",
    "beta = model.params\n",
    "print('参数估计值: \\n', round(beta, 4))\n",
    "X = data[:, 0 : p + 1]\n",
    "Y = data[:, -1]\n",
    "Y_hat = model.fittedvalues\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d76f2a9",
   "metadata": {},
   "source": [
    "## 综上所述，我们可以输出多元线性回归方程 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f7256d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_hat = -266.03 + (0.01 * X1) + (3.13 * X2) + (1.87 * X3)\n"
     ]
    }
   ],
   "source": [
    "print('Y_hat = %.2f + (%.2f * X1) + (%.2f * X2) + (%.2f * X3)' % (beta[0], beta[1], beta[2], beta[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d0c7c7",
   "metadata": {},
   "source": [
    "# Task 2: 分别将数据中心化、标准化之后，比较参数估计的异同，并进行评述（提示：可以结合理论课的课件）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2adbd82",
   "metadata": {},
   "source": [
    "## 中心化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238dc9b5",
   "metadata": {},
   "source": [
    "### 课上代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b306c5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>Brake_Horsepower</td> <th>  R-squared:         </th> <td>   0.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 07 Oct 2023</td> <th>  Prob (F-statistic):</th>  <td>0.00317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:22:14</td>     <th>  Log-Likelihood:    </th> <td> -40.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    12</td>      <th>  AIC:               </th> <td>   89.42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     8</td>      <th>  BIC:               </th> <td>   91.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td> -266.0312</td> <td>   92.674</td> <td>   -2.871</td> <td> 0.021</td> <td> -479.737</td> <td>  -52.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rpm</th>                <td>    0.0107</td> <td>    0.004</td> <td>    2.390</td> <td> 0.044</td> <td>    0.000</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Road_Octane_Number</th> <td>    3.1348</td> <td>    0.844</td> <td>    3.712</td> <td> 0.006</td> <td>    1.188</td> <td>    5.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Compression</th>        <td>    1.8674</td> <td>    0.535</td> <td>    3.494</td> <td> 0.008</td> <td>    0.635</td> <td>    3.100</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.392</td> <th>  Durbin-Watson:     </th> <td>   1.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.822</td> <th>  Jarque-Bera (JB):  </th> <td>   0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.282</td> <th>  Prob(JB):          </th> <td>   0.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.625</td> <th>  Cond. No.          </th> <td>9.03e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.03e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       & Brake\\_Horsepower & \\textbf{  R-squared:         } &     0.807   \\\\\n",
       "\\textbf{Model:}               &        OLS        & \\textbf{  Adj. R-squared:    } &     0.734   \\\\\n",
       "\\textbf{Method:}              &   Least Squares   & \\textbf{  F-statistic:       } &     11.12   \\\\\n",
       "\\textbf{Date:}                &  Sat, 07 Oct 2023 & \\textbf{  Prob (F-statistic):} &  0.00317    \\\\\n",
       "\\textbf{Time:}                &      15:22:14     & \\textbf{  Log-Likelihood:    } &   -40.708   \\\\\n",
       "\\textbf{No. Observations:}    &           12      & \\textbf{  AIC:               } &     89.42   \\\\\n",
       "\\textbf{Df Residuals:}        &            8      & \\textbf{  BIC:               } &     91.36   \\\\\n",
       "\\textbf{Df Model:}            &            3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}     &     nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}            &    -266.0312  &       92.674     &    -2.871  &         0.021        &     -479.737    &      -52.325     \\\\\n",
       "\\textbf{rpm}                  &       0.0107  &        0.004     &     2.390  &         0.044        &        0.000    &        0.021     \\\\\n",
       "\\textbf{Road\\_Octane\\_Number} &       3.1348  &        0.844     &     3.712  &         0.006        &        1.188    &        5.082     \\\\\n",
       "\\textbf{Compression}          &       1.8674  &        0.535     &     3.494  &         0.008        &        0.635    &        3.100     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.392 & \\textbf{  Durbin-Watson:     } &    1.043  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.822 & \\textbf{  Jarque-Bera (JB):  } &    0.230  \\\\\n",
       "\\textbf{Skew:}          & -0.282 & \\textbf{  Prob(JB):          } &    0.891  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.625 & \\textbf{  Cond. No.          } & 9.03e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 9.03e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       Brake_Horsepower   R-squared:                       0.807\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     11.12\n",
       "Date:                Sat, 07 Oct 2023   Prob (F-statistic):            0.00317\n",
       "Time:                        15:22:14   Log-Likelihood:                -40.708\n",
       "No. Observations:                  12   AIC:                             89.42\n",
       "Df Residuals:                       8   BIC:                             91.36\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept           -266.0312     92.674     -2.871      0.021    -479.737     -52.325\n",
       "rpm                    0.0107      0.004      2.390      0.044       0.000       0.021\n",
       "Road_Octane_Number     3.1348      0.844      3.712      0.006       1.188       5.082\n",
       "Compression            1.8674      0.535      3.494      0.008       0.635       3.100\n",
       "==============================================================================\n",
       "Omnibus:                        0.392   Durbin-Watson:                   1.043\n",
       "Prob(Omnibus):                  0.822   Jarque-Bera (JB):                0.230\n",
       "Skew:                          -0.282   Prob(JB):                        0.891\n",
       "Kurtosis:                       2.625   Cond. No.                     9.03e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.03e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "be7ac440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample means of centered features are  [-0. -0.  0.]\n",
      "The sample mean of centered response is  0.0\n"
     ]
    }
   ],
   "source": [
    "## 中心化\n",
    "Data1 = sm.add_constant(Data)\n",
    "Data1_value = Data1.values\n",
    "X = Data1_value[:,0:(p+1)]\n",
    "y = Data1_value[:,-1]\n",
    "X_center = preprocessing.scale(X_without_intercept, with_mean = True, with_std=False)\n",
    "y_center = preprocessing.scale(y, with_mean = True, with_std=False)\n",
    "# with_mean = True (default), with_std = True (default)\n",
    "\n",
    "# print(X_center) \n",
    "\n",
    "print(\"The sample means of centered features are \", np.around(np.mean(X_center,axis=0),4))\n",
    "print(\"The sample mean of centered response is \", np.around(np.mean(y_center,axis=0),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fe078115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimates of the parameters are \n",
      " [0.     0.0107 3.1348 1.8674]\n"
     ]
    }
   ],
   "source": [
    "model3 = linear_model.LinearRegression()\n",
    "model3.fit(X_center, y_center)\n",
    "beta_hat_4 = np.append(np.array(model3.intercept_),model3.coef_)\n",
    "print(\"The estimates of the parameters are \\n\", \n",
    "          np.around(beta_hat_4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eace4391",
   "metadata": {},
   "source": [
    "### 自己尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8e14d05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数估计值: \n",
      " Intercept    0.0000\n",
      "P1_cent      0.0107\n",
      "P2_cent      3.1348\n",
      "P3_cent      1.8674\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>F_cent</td>      <th>  R-squared:         </th> <td>   0.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 07 Oct 2023</td> <th>  Prob (F-statistic):</th>  <td>0.00317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:22:16</td>     <th>  Log-Likelihood:    </th> <td> -40.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    12</td>      <th>  AIC:               </th> <td>   89.42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     8</td>      <th>  BIC:               </th> <td>   91.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  1.11e-16</td> <td>    2.544</td> <td> 4.36e-17</td> <td> 1.000</td> <td>   -5.866</td> <td>    5.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P1_cent</th>   <td>    0.0107</td> <td>    0.004</td> <td>    2.390</td> <td> 0.044</td> <td>    0.000</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P2_cent</th>   <td>    3.1348</td> <td>    0.844</td> <td>    3.712</td> <td> 0.006</td> <td>    1.188</td> <td>    5.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P3_cent</th>   <td>    1.8674</td> <td>    0.535</td> <td>    3.494</td> <td> 0.008</td> <td>    0.635</td> <td>    3.100</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.392</td> <th>  Durbin-Watson:     </th> <td>   1.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.822</td> <th>  Jarque-Bera (JB):  </th> <td>   0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.282</td> <th>  Prob(JB):          </th> <td>   0.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.625</td> <th>  Cond. No.          </th> <td>    574.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &     F\\_cent      & \\textbf{  R-squared:         } &     0.807   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.734   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     11.12   \\\\\n",
       "\\textbf{Date:}             & Sat, 07 Oct 2023 & \\textbf{  Prob (F-statistic):} &  0.00317    \\\\\n",
       "\\textbf{Time:}             &     15:22:16     & \\textbf{  Log-Likelihood:    } &   -40.708   \\\\\n",
       "\\textbf{No. Observations:} &          12      & \\textbf{  AIC:               } &     89.42   \\\\\n",
       "\\textbf{Df Residuals:}     &           8      & \\textbf{  BIC:               } &     91.36   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &     1.11e-16  &        2.544     &  4.36e-17  &         1.000        &       -5.866    &        5.866     \\\\\n",
       "\\textbf{P1\\_cent}  &       0.0107  &        0.004     &     2.390  &         0.044        &        0.000    &        0.021     \\\\\n",
       "\\textbf{P2\\_cent}  &       3.1348  &        0.844     &     3.712  &         0.006        &        1.188    &        5.082     \\\\\n",
       "\\textbf{P3\\_cent}  &       1.8674  &        0.535     &     3.494  &         0.008        &        0.635    &        3.100     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.392 & \\textbf{  Durbin-Watson:     } &    1.043  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.822 & \\textbf{  Jarque-Bera (JB):  } &    0.230  \\\\\n",
       "\\textbf{Skew:}          & -0.282 & \\textbf{  Prob(JB):          } &    0.891  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.625 & \\textbf{  Cond. No.          } &     574.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 F_cent   R-squared:                       0.807\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     11.12\n",
       "Date:                Sat, 07 Oct 2023   Prob (F-statistic):            0.00317\n",
       "Time:                        15:22:16   Log-Likelihood:                -40.708\n",
       "No. Observations:                  12   AIC:                             89.42\n",
       "Df Residuals:                       8   BIC:                             91.36\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    1.11e-16      2.544   4.36e-17      1.000      -5.866       5.866\n",
       "P1_cent        0.0107      0.004      2.390      0.044       0.000       0.021\n",
       "P2_cent        3.1348      0.844      3.712      0.006       1.188       5.082\n",
       "P3_cent        1.8674      0.535      3.494      0.008       0.635       3.100\n",
       "==============================================================================\n",
       "Omnibus:                        0.392   Durbin-Watson:                   1.043\n",
       "Prob(Omnibus):                  0.822   Jarque-Bera (JB):                0.230\n",
       "Skew:                          -0.282   Prob(JB):                        0.891\n",
       "Kurtosis:                       2.625   Cond. No.                         574.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[:, 0 : p + 1]\n",
    "Y = data[:, -1]\n",
    "# 求均值\n",
    "X_mean = []\n",
    "for k in range(p + 1):\n",
    "    X_mean.append(np.mean(data[:, k]))  # 自变量 x 的均值\n",
    "Y_mean = np.mean(data[:, -1])  # 因变量 y 的均值\n",
    "\n",
    "# 数据中心化\n",
    "X_cent = X - X_mean\n",
    "Y_cent = Y - Y_mean\n",
    "\n",
    "# Do the multiple linear regression\n",
    "df = pd.DataFrame(X_cent, columns = ['intercept_cent', 'P1_cent', 'P2_cent', 'P3_cent'])\n",
    "df['F_cent'] = Y_cent\n",
    "model_cent = ols('F_cent ~ P1_cent + P2_cent + P3_cent', df).fit()\n",
    "beta_cent = model_cent.params\n",
    "print('参数估计值: \\n', round(beta_cent, 4))\n",
    "Y_hat_cent = model_cent.fittedvalues\n",
    "model_cent.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14a4327",
   "metadata": {},
   "source": [
    "### 输出中心化后的多元线性回归方程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "43ffe8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_hat_cent = 0.00 + (0.01 * X1_cent) + (3.13 * X2_cent) + (1.87 * X3_cent)\n"
     ]
    }
   ],
   "source": [
    "print('Y_hat_cent = %.2f + (%.2f * X1_cent) + (%.2f * X2_cent) + (%.2f * X3_cent)' % (beta_cent[0], beta_cent[1], beta_cent[2], beta_cent[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4832577",
   "metadata": {},
   "source": [
    "### 通过对比数据中心化前后的结果，我们可以发现，对数据进行中心化之后回归常数变为 0，而回归系数值未改变。\n",
    "**回归常数变为0的原因**是中心化的过程中，自变量 X 被减去了它们的均值，这样在回归模型中，截距项对应的是因变量Y在所有自变量均为均值时的预测值，因此截距项会变为0。\n",
    "\n",
    "**回归系数值未改变的原因**是中心化不会改变自变量之间的相对关系，因此回归系数的值保持不变。\n",
    "\n",
    "中心化主要的作用是消除了截距项与自变量之间的关系，使模型更容易解释，但不会影响自变量对因变量的影响程度。模型中的回归系数仍然表示每个自变量对因变量的影响大小，只是解释上更容易理解。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fef13d0",
   "metadata": {},
   "source": [
    "## 标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "efaef396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数估计值: \n",
      " Intercept    0.0000\n",
      "P1_std       0.3757\n",
      "P2_std       0.5793\n",
      "P3_std       0.5477\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>F_std</td>      <th>  R-squared:         </th> <td>   0.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 07 Oct 2023</td> <th>  Prob (F-statistic):</th>  <td>0.00317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:22:18</td>     <th>  Log-Likelihood:    </th> <td> -7.1718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    12</td>      <th>  AIC:               </th> <td>   22.34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     8</td>      <th>  BIC:               </th> <td>   24.28</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 1.735e-17</td> <td>    0.156</td> <td> 1.12e-16</td> <td> 1.000</td> <td>   -0.359</td> <td>    0.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P1_std</th>    <td>    0.3757</td> <td>    0.157</td> <td>    2.390</td> <td> 0.044</td> <td>    0.013</td> <td>    0.738</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P2_std</th>    <td>    0.5793</td> <td>    0.156</td> <td>    3.712</td> <td> 0.006</td> <td>    0.219</td> <td>    0.939</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P3_std</th>    <td>    0.5477</td> <td>    0.157</td> <td>    3.494</td> <td> 0.008</td> <td>    0.186</td> <td>    0.909</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.392</td> <th>  Durbin-Watson:     </th> <td>   1.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.822</td> <th>  Jarque-Bera (JB):  </th> <td>   0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.282</td> <th>  Prob(JB):          </th> <td>   0.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.625</td> <th>  Cond. No.          </th> <td>    1.16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      F\\_std      & \\textbf{  R-squared:         } &     0.807   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.734   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     11.12   \\\\\n",
       "\\textbf{Date:}             & Sat, 07 Oct 2023 & \\textbf{  Prob (F-statistic):} &  0.00317    \\\\\n",
       "\\textbf{Time:}             &     15:22:18     & \\textbf{  Log-Likelihood:    } &   -7.1718   \\\\\n",
       "\\textbf{No. Observations:} &          12      & \\textbf{  AIC:               } &     22.34   \\\\\n",
       "\\textbf{Df Residuals:}     &           8      & \\textbf{  BIC:               } &     24.28   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &    1.735e-17  &        0.156     &  1.12e-16  &         1.000        &       -0.359    &        0.359     \\\\\n",
       "\\textbf{P1\\_std}   &       0.3757  &        0.157     &     2.390  &         0.044        &        0.013    &        0.738     \\\\\n",
       "\\textbf{P2\\_std}   &       0.5793  &        0.156     &     3.712  &         0.006        &        0.219    &        0.939     \\\\\n",
       "\\textbf{P3\\_std}   &       0.5477  &        0.157     &     3.494  &         0.008        &        0.186    &        0.909     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.392 & \\textbf{  Durbin-Watson:     } &    1.043  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.822 & \\textbf{  Jarque-Bera (JB):  } &    0.230  \\\\\n",
       "\\textbf{Skew:}          & -0.282 & \\textbf{  Prob(JB):          } &    0.891  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.625 & \\textbf{  Cond. No.          } &     1.16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  F_std   R-squared:                       0.807\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     11.12\n",
       "Date:                Sat, 07 Oct 2023   Prob (F-statistic):            0.00317\n",
       "Time:                        15:22:18   Log-Likelihood:                -7.1718\n",
       "No. Observations:                  12   AIC:                             22.34\n",
       "Df Residuals:                       8   BIC:                             24.28\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.735e-17      0.156   1.12e-16      1.000      -0.359       0.359\n",
       "P1_std         0.3757      0.157      2.390      0.044       0.013       0.738\n",
       "P2_std         0.5793      0.156      3.712      0.006       0.219       0.939\n",
       "P3_std         0.5477      0.157      3.494      0.008       0.186       0.909\n",
       "==============================================================================\n",
       "Omnibus:                        0.392   Durbin-Watson:                   1.043\n",
       "Prob(Omnibus):                  0.822   Jarque-Bera (JB):                0.230\n",
       "Skew:                          -0.282   Prob(JB):                        0.891\n",
       "Kurtosis:                       2.625   Cond. No.                         1.16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[:, 0 : p + 1]\n",
    "Y = data[:, -1]\n",
    "# 求均值\n",
    "X_mean = []\n",
    "for k in range(p + 1):\n",
    "    X_mean.append(np.mean(data[:, k]))  # 自变量 x 的均值\n",
    "Y_mean = np.mean(data[:, -1])  # 因变量 y 的均值\n",
    "\n",
    "# 标准化\n",
    "X_std = (X - X_mean) / np.std(X, axis=0)\n",
    "Y_std = (Y - Y_mean) / np.std(Y)\n",
    "\n",
    "# Do the multiple linear regression\n",
    "df = pd.DataFrame(X_std, columns=['intercept_std', 'P1_std', 'P2_std', 'P3_std'])\n",
    "df['F_std'] = Y_std\n",
    "model_std = ols('F_std ~ P1_std + P2_std + P3_std', df).fit()\n",
    "beta_std = model_std.params\n",
    "print('参数估计值: \\n', round(beta_std, 4))\n",
    "Y_hat_std = model_std.fittedvalues\n",
    "model_std.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41b4cf3",
   "metadata": {},
   "source": [
    "### 输出标准化后的多元线性回归方程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "45e3b856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_hat_std = 0.00 + (0.38 * X1_std) + (0.58 * X2_std) + (0.55 * X3_std)\n"
     ]
    }
   ],
   "source": [
    "print('Y_hat_std = %.2f + (%.2f * X1_std) + (%.2f * X2_std) + (%.2f * X3_std)' % (beta_std[0], beta_std[1], beta_std[2], beta_std[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6861830b",
   "metadata": {},
   "source": [
    "### 通过对比数据标准化前后的结果，我们可以发现，参数的正负号不变、大小和原来的参数之间存在关系\n",
    "**参数的正负号不变的原因**是标准化数据不会改变自变量之间的相对关系，因此回归系数的方向（正负号）仍然保持不变。\n",
    "\n",
    "**大小和原来的参数之间存在关系的原因**标准化后的回归系数可以直接比较各自变量对因变量的影响程度。如果自变量的取值范围差异较大，标准化后的回归系数可以用来衡量它们的相对影响。标准化后的回归系数表示因变量 Y 在单位标准差变化下对每个自变量的变化量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92286fcf",
   "metadata": {},
   "source": [
    "# Task 3: 从模型显著性、参数显著性以及残差分析三个角度，分析多元线性回归模型是否合理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e04c803",
   "metadata": {},
   "source": [
    "### 1、模型显著性和参数显著性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63167d41",
   "metadata": {},
   "source": [
    "#### 课上代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7a875dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>Brake_Horsepower</td> <th>  R-squared:         </th> <td>   0.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 07 Oct 2023</td> <th>  Prob (F-statistic):</th>  <td>0.00317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:22:21</td>     <th>  Log-Likelihood:    </th> <td> -40.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    12</td>      <th>  AIC:               </th> <td>   89.42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     8</td>      <th>  BIC:               </th> <td>   91.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td> -266.0312</td> <td>   92.674</td> <td>   -2.871</td> <td> 0.021</td> <td> -479.737</td> <td>  -52.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rpm</th>                <td>    0.0107</td> <td>    0.004</td> <td>    2.390</td> <td> 0.044</td> <td>    0.000</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Road_Octane_Number</th> <td>    3.1348</td> <td>    0.844</td> <td>    3.712</td> <td> 0.006</td> <td>    1.188</td> <td>    5.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Compression</th>        <td>    1.8674</td> <td>    0.535</td> <td>    3.494</td> <td> 0.008</td> <td>    0.635</td> <td>    3.100</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.392</td> <th>  Durbin-Watson:     </th> <td>   1.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.822</td> <th>  Jarque-Bera (JB):  </th> <td>   0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.282</td> <th>  Prob(JB):          </th> <td>   0.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.625</td> <th>  Cond. No.          </th> <td>9.03e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.03e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       & Brake\\_Horsepower & \\textbf{  R-squared:         } &     0.807   \\\\\n",
       "\\textbf{Model:}               &        OLS        & \\textbf{  Adj. R-squared:    } &     0.734   \\\\\n",
       "\\textbf{Method:}              &   Least Squares   & \\textbf{  F-statistic:       } &     11.12   \\\\\n",
       "\\textbf{Date:}                &  Sat, 07 Oct 2023 & \\textbf{  Prob (F-statistic):} &  0.00317    \\\\\n",
       "\\textbf{Time:}                &      15:22:21     & \\textbf{  Log-Likelihood:    } &   -40.708   \\\\\n",
       "\\textbf{No. Observations:}    &           12      & \\textbf{  AIC:               } &     89.42   \\\\\n",
       "\\textbf{Df Residuals:}        &            8      & \\textbf{  BIC:               } &     91.36   \\\\\n",
       "\\textbf{Df Model:}            &            3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}     &     nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}            &    -266.0312  &       92.674     &    -2.871  &         0.021        &     -479.737    &      -52.325     \\\\\n",
       "\\textbf{rpm}                  &       0.0107  &        0.004     &     2.390  &         0.044        &        0.000    &        0.021     \\\\\n",
       "\\textbf{Road\\_Octane\\_Number} &       3.1348  &        0.844     &     3.712  &         0.006        &        1.188    &        5.082     \\\\\n",
       "\\textbf{Compression}          &       1.8674  &        0.535     &     3.494  &         0.008        &        0.635    &        3.100     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.392 & \\textbf{  Durbin-Watson:     } &    1.043  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.822 & \\textbf{  Jarque-Bera (JB):  } &    0.230  \\\\\n",
       "\\textbf{Skew:}          & -0.282 & \\textbf{  Prob(JB):          } &    0.891  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.625 & \\textbf{  Cond. No.          } & 9.03e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 9.03e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       Brake_Horsepower   R-squared:                       0.807\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     11.12\n",
       "Date:                Sat, 07 Oct 2023   Prob (F-statistic):            0.00317\n",
       "Time:                        15:22:21   Log-Likelihood:                -40.708\n",
       "No. Observations:                  12   AIC:                             89.42\n",
       "Df Residuals:                       8   BIC:                             91.36\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept           -266.0312     92.674     -2.871      0.021    -479.737     -52.325\n",
       "rpm                    0.0107      0.004      2.390      0.044       0.000       0.021\n",
       "Road_Octane_Number     3.1348      0.844      3.712      0.006       1.188       5.082\n",
       "Compression            1.8674      0.535      3.494      0.008       0.635       3.100\n",
       "==============================================================================\n",
       "Omnibus:                        0.392   Durbin-Watson:                   1.043\n",
       "Prob(Omnibus):                  0.822   Jarque-Bera (JB):                0.230\n",
       "Skew:                          -0.282   Prob(JB):                        0.891\n",
       "Kurtosis:                       2.625   Cond. No.                     9.03e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.03e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902a9e59",
   "metadata": {},
   "source": [
    "从上表可知，\n",
    "- $F$检验统计量可以计算为11.12，其$p$值为$0.00317$。因此，我们认为回归模型是有意义的。\n",
    "- 对于不同的特征，$t$检验统计量分别为$2.390和$3.712$和$3.494 \t$，其$p$值均不大于$0.05 。因此，我们认为这三个特征都是有意义的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205dd767",
   "metadata": {},
   "source": [
    "### 自己实践"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "63d0043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 求解相关项\n",
    "SSE = sum((Y - Y_hat) ** 2)\n",
    "SST = sum((Y - Y_mean) ** 2)\n",
    "SSR = sum((Y_hat - Y_mean) ** 2)\n",
    "\n",
    "sigma2 = SSE / (n - p - 1)  # 方差\n",
    "sigma = np.sqrt(sigma2)  # 标准差\n",
    "\n",
    "c = np.dot(X.T, X)\n",
    "C = np.linalg.inv(c)  # 求逆\n",
    "# print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b102abd8",
   "metadata": {},
   "source": [
    "**多元线性模型的显著性检验——F 检验:**  \n",
    "检验假设：$H_0: \\beta_1=\\beta_2=\\beta_3=0$ vs $H_1: \\exists \\beta_i \\neq 0,i=1,2,3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "90fc3c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F0: 11.12\n",
      "pVal1: 0.00317\n",
      "\n",
      "Since p-value < 0.05, reject H0.\n",
      "Since F0 > F(0.95, 3, 8) = 4.07, reject H0.\n"
     ]
    }
   ],
   "source": [
    "# 计算F0\n",
    "F0 = (SSR / p) / (SSE / (n - p - 1))\n",
    "# F0 = model.fvalue\n",
    "print('F0: %.2f' % F0)\n",
    "F = round(f.ppf(0.95, dfn = p, dfd = n - p - 1), 2)\n",
    "\n",
    "# 法1：\n",
    "pVal1 = f.sf(F0, p, n - p - 1)\n",
    "# pVal1 = model.f_pvalue\n",
    "print('pVal1: %.5f' % pVal1)\n",
    "if pVal1 < alpha:\n",
    "    print('\\nSince p-value < 0.05, reject H0.')\n",
    "else:\n",
    "    print('\\nAccept H0.') \n",
    "\n",
    "# 法2：\n",
    "if F0 > F:\n",
    "    print('Since F0 > F(0.95, 3, 8) = %.2f, reject H0.' % F)\n",
    "else:\n",
    "    print('Accept H0.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9827e7",
   "metadata": {},
   "source": [
    "由 F 检验结果可知，该回归方程是显著的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852d23eb",
   "metadata": {},
   "source": [
    "**多元线性模型的显著性检验——t 检验:**  \n",
    "检验假设：$H_{0j}: \\beta_j=0$ vs $H_{1j}: \\beta_j \\neq 0,j=1,2,3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "47d65aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t0值为： [-2.8706  2.3896  3.7123  3.4936]\n",
      "t的临界值为：2.3060\n",
      "P值为： [0.0104 0.0219 0.003  0.0041]\n",
      "\n",
      "\n",
      "Since p1-value < 0.05, reject H01.\n",
      "Since p2-value < 0.05, reject H02.\n",
      "Since p3-value < 0.05, reject H03.\n",
      "\n",
      "\n",
      "Since t01 > t(0.975, 8) = 2.3060, reject H01\n",
      "Since t02 > t(0.975, 8) = 2.3060, reject H02\n",
      "Since t03 > t(0.975, 8) = 2.3060, reject H03\n"
     ]
    }
   ],
   "source": [
    "# t检验\n",
    "t0 = []\n",
    "for i in range(p + 1):   \n",
    "    t0.append(beta[i] / (np.sqrt(C[i][i] * sigma2)))  # 求t值\n",
    "# t0 = model.tvalues\n",
    "print('t0值为：', np.round(t0, 4))\n",
    "tVal = t.ppf(1 - alpha / 2, n - p - 1)\n",
    "print('t的临界值为：%.4f' % tVal)\n",
    "pVal2 = []\n",
    "for i in range(p + 1):\n",
    "    P = t.sf(abs(t0[i]), n - p - 1)\n",
    "    pVal2.append(P)  # 已知临界值求p值\n",
    "# pVal2 = model.pvalues / 2\n",
    "print('P值为：', np.round(pVal2, 4))\n",
    "\n",
    "print('\\n')\n",
    "# 法1：\n",
    "for i in range(p):\n",
    "    if pVal2[i + 1] < alpha:\n",
    "        print ('Since p%d-value < 0.05, reject H0%d.' % (i + 1, i + 1))\n",
    "    else:\n",
    "        print('Accept H0%d.' % (i + 1))\n",
    "print('\\n')   \n",
    "\n",
    "# 法2：\n",
    "for i in range(p):\n",
    "    if abs(t0[i + 1]) > tVal:\n",
    "        print('Since t0%d > t(0.975, 8) = %.4f, reject H0%d' % (i + 1, tVal, i + 1))\n",
    "    else:\n",
    "        print('Accept H0%d.' % (i + 1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9777f592",
   "metadata": {},
   "source": [
    "由 t 检验结果可知，各回归系数都是显著的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946ccc12",
   "metadata": {},
   "source": [
    "**复相关系数（可决系数）的检验:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7ea1f",
   "metadata": {},
   "source": [
    "定义样本决定系数为\n",
    "$$\n",
    "R^{2}=\\frac{S S_{R}}{S S_{T}}=1-\\frac{S S_{E}}{S S_{T}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6d2623",
   "metadata": {},
   "source": [
    "$R^{2}$ 的取值在 [0,1] 区间内。\n",
    "\n",
    "1. $R^{2}$ 越接近 $1,$ 表明回归拟合的效果越好。\n",
    "2. $R^{2}$ 越接近 $0,$ 表明回归拟合的效果越差。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2c84f",
   "metadata": {},
   "source": [
    "调整可决系数：\n",
    "\n",
    "$$R_{a}^{2}=1-\\frac{n-1}{n-m-1}\\left(1-R^{2}\\right)$$\n",
    "\n",
    "随着变量个数上升，$R^{2}$会增大而影响决定系数的准确度，所以引入惩罚项加以修正，称之 $adjusted R^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "838cef60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可决系数：0.8065\n",
      "调整可决系数Ra：0.7340\n"
     ]
    }
   ],
   "source": [
    "# 可决系数\n",
    "R2 = SSR / SST\n",
    "print('可决系数：%.4f' % R2)\n",
    "\n",
    "# 调整可决系数\n",
    "R2c = 1 - (SSE/(n-p-1)) / (SST/(n-1))\n",
    "print('调整可决系数Ra：%.4f' % R2c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10e2444",
   "metadata": {},
   "source": [
    "由于复相关系数（可决系数）值接近1，可以说明整体上 $X_1$,$X_2$,$X_3$与 $Y$ 呈线性关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90daf6f",
   "metadata": {},
   "source": [
    "### 2、残差分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0994c143",
   "metadata": {},
   "source": [
    "###  计算Brake_Horsepower的残差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a59a5781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   intercept      P1    P2     P3      F_res\n",
      "0        1.0  2000.0  90.0  100.0   0.731289\n",
      "1        1.0  1800.0  94.0   95.0 -13.328247\n",
      "2        1.0  2400.0  88.0  110.0 -11.958476\n",
      "3        1.0  1900.0  91.0   96.0   3.137442\n",
      "4        1.0  1600.0  86.0  100.0  11.555798\n"
     ]
    }
   ],
   "source": [
    "# 计算制动马力的残差\n",
    "data_res = data * 1.0  # 乘1.0 不然会损失精度\n",
    "for i in range(n):\n",
    "    data_res[:, p + 1] = Y - Y_hat\n",
    "df = pd.DataFrame(data_res, columns = ['intercept', 'P1', 'P2', 'P3', 'F_res'])\n",
    "res = data_res[:, p + 1]\n",
    "# res = model.resid\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec0110c",
   "metadata": {},
   "source": [
    "### 残差的正态概率图   \n",
    "使用残差正态概率图可验证残差呈正态分布的假设。残差的正态概率图应该大致为一条直线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e5e6575b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 残差的正态概率图\n",
    "osm, osr = stats.probplot(res, dist = 'norm', plot = plt)\n",
    "x = osm[0][0]\n",
    "y = osm[1][0]\n",
    "plt.text(x, y, '%.2f' % float(y), ha='center', va= 'bottom', fontsize=9)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bf84f7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "残差 -13.33 不是异常值.\n"
     ]
    }
   ],
   "source": [
    "# 异常值检验\n",
    "MSE = SSE / (n - p - 1)\n",
    "# MSE = model.mse_resid\n",
    "d = np.abs(y) / np.sqrt(MSE)\n",
    "if d < 3:\n",
    "    print('残差', round(y, 2), '不是异常值.')\n",
    "else:\n",
    "    print('残差', round(y, 2), '是异常值')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef068745",
   "metadata": {},
   "source": [
    "从残差的正态概率图可以看出，这些点大致在一条直线附近，说明数据近似服从正态分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7ee8e6",
   "metadata": {},
   "source": [
    "### 残差与拟合值的关系图   \n",
    "使用残差与拟合值图可验证“残差随机分布”和“具有常量方差”的假设。理想情况下，点应当在 0 的两端随机分布（模型的拟合点应该平均散布在被拟合值点附近），点中无可辨识的模式。  \n",
    "下表中的模式可能表示该模型不满足模型假设: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df759ea2",
   "metadata": {},
   "source": [
    "| 模式 | 模式的含义 |\n",
    "| :----------: | :--------: |\n",
    "| 残差相对拟合值呈扇形或不均匀分散 | 异方差 |\n",
    "| 曲线 | 缺少高阶项 |\n",
    "| 远离 0 的点 | 异常值 |\n",
    "| 在 X 方向远离其他点的点 | 有影响的点|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aea320e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'e_i')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 残差与拟合值的关系图\n",
    "plt.scatter(Y_hat, res, c = 'red')\n",
    "plt.title('Plot of residuals versus y_i')\n",
    "plt.xlabel('y_i')\n",
    "plt.ylabel('e_i')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80a9dc2",
   "metadata": {},
   "source": [
    "从残差与拟合值的关系图中，无法拒绝方差齐性的假设。所以不能认为模型不合理，即认为模型合理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fcad07",
   "metadata": {},
   "source": [
    "#### 方差分析可以看成特殊情况下的回归分析，方差分析就是解释变量全为分组的dummy（哑变量）的回归分析。  \n",
    "\n",
    "方差齐性检验的本质：样本以及总体的方差分布是常数，和自变量或因变量没关系。    \n",
    "线性回归里面我们一般用残差图来检验方差齐性，画散点图是为了弄清因变量和残差之间有没有关系。这里并不是说不同指标的方差不同，因为这里的自变量不像ANOVA中是可以人为控制的（分组-取值），这里的自变量是**观察**到的，如果我们没法取到每个 x 值所有对应的 y 值，就不能说对不同的指标方差不同，只是说观测值的方差不同（也只是一种探测）；我们这里只是用残差图去估计因变量的方差齐性（比较主观，看残差分布是否与拟合值没有明显的趋势关系）。  \n",
    "当然我们并不能通过残差的分布来证明因变量的方差齐性，我们只是提出了“方差齐性”的假设，然后画出残差图，它杂乱无章，不相关，看起来是独立的，所以我们不能推翻这个假设，就认为观测值的方差是齐性的。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec94f873",
   "metadata": {},
   "source": [
    "# Task 4: 若取发动机转速为3000转/min，道路辛烷值为90，发动机压缩值为100时，分别给出制动马力值的置信区间和预测区间。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6c33c3",
   "metadata": {},
   "source": [
    "#### 注意两者的计算方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e34aab",
   "metadata": {},
   "source": [
    "**Remark3**: 多元情况下依然有预测区间的长度大于置信区间，借机温习一下二者的计算方法\n",
    "\n",
    "预测区间：\n",
    "\n",
    "$$\n",
    "(\\hat{y}_{f}-t_{\\alpha/2}*\\sqrt{(1+\\frac{1}{n}+\\frac{x_{f}-\\bar{x}}{\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}})\\sigma^{2}},\\hat{y}_{f}+t_{\\alpha/2}*\\sqrt{(1+\\frac{1}{n}+\\frac{x_{f}-\\bar{x}}{\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}})\\sigma^{2}}$$\n",
    "\n",
    "置信区间：\n",
    "\n",
    "$$\n",
    "(\\hat{y}_{f}-t_{\\alpha/2}*\\sqrt{(\\frac{1}{n}+\\frac{x_{f}-\\bar{x}}{\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}})\\sigma^{2}},\\hat{y}_{f}+t_{\\alpha/2}*\\sqrt{(\\frac{1}{n}+\\frac{x_{f}-\\bar{x}}{\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}})\\sigma^{2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e49655",
   "metadata": {},
   "source": [
    "### 置信区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b37b493f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "90\n",
      "100\n",
      "8.736173458784997\n",
      "给定 x =  [1, 3000, 90, 100] , E(y_0) 的置信区间： [226.2457 243.7181]\n",
      "8.736173458784997\n",
      "8.736173458784997\n",
      "宽度 =  17.472399999999993\n"
     ]
    }
   ],
   "source": [
    "# 给定 x_0，求 E(y_0) 的估计值\n",
    "def confidence_interval(x0):\n",
    "    x0 = np.array(x0)\n",
    "    Y0 = np.dot(x0.T, beta)\n",
    "    delta0 = tVal * sigma * np.sqrt(x0.T @ C @ x0)\n",
    "    Y0_int = [Y0 - delta0, Y0 + delta0]\n",
    "    print(delta0)\n",
    "    return Y0_int\n",
    "\n",
    "x0 = [1]\n",
    "for i in range(p):\n",
    "    x0.append(int(input()))\n",
    "print('给定 x = ', x0, ', E(y_0) 的置信区间：', np.round(confidence_interval(x0), 4))\n",
    "print('宽度 = ',np.round(confidence_interval(x0), 4)[1]-np.round(confidence_interval(x0), 4)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a8ce94",
   "metadata": {},
   "source": [
    "### 预测区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9578381a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "90\n",
      "100\n",
      "给定 x =  [1, 3000, 90, 100] , y_0 的预测区间： [212.8622 257.1016]\n",
      "宽度 =  44.23940000000002\n"
     ]
    }
   ],
   "source": [
    "# 给定 x_0，求 y_0 的预测区间\n",
    "def confidence_interval(x0):\n",
    "    x0 = np.array(x0)\n",
    "    Y0 = np.dot(x0.T, beta)\n",
    "    delta1 = tVal * sigma * np.sqrt(1 + x0.T @ C @ x0)\n",
    "    Y0_int = [Y0 - delta1, Y0 + delta1]\n",
    "    return Y0_int\n",
    "\n",
    "x0_ = [1]\n",
    "for i in range(p):\n",
    "    x0_.append(int(input()))\n",
    "print('给定 x = ', x0_, ', y_0 的预测区间：', np.round(confidence_interval(x0_), 4))\n",
    "print('宽度 = ',np.round(confidence_interval(x0), 4)[1]-np.round(confidence_interval(x0), 4)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fead80",
   "metadata": {},
   "source": [
    "从上面的差值可以看出，宽度44.23>17.47，符合预测区间大于置信区间的逻辑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd8c0be",
   "metadata": {},
   "source": [
    "### 遇到的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43237c2f",
   "metadata": {},
   "source": [
    "#### 1、标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "433464d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数估计值: \n",
      " Intercept      0.0000\n",
      "P1_std         0.6913\n",
      "P2_std       202.2802\n",
      "P3_std       120.4986\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>F_std</td>      <th>  R-squared:         </th> <td>   0.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 07 Oct 2023</td> <th>  Prob (F-statistic):</th>  <td>0.00317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:22:49</td>     <th>  Log-Likelihood:    </th> <td> -7.1718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    12</td>      <th>  AIC:               </th> <td>   22.34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     8</td>      <th>  BIC:               </th> <td>   24.28</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 1.735e-17</td> <td>    0.156</td> <td> 1.12e-16</td> <td> 1.000</td> <td>   -0.359</td> <td>    0.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P1_std</th>    <td>    0.6913</td> <td>    0.289</td> <td>    2.390</td> <td> 0.044</td> <td>    0.024</td> <td>    1.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P2_std</th>    <td>  202.2802</td> <td>   54.489</td> <td>    3.712</td> <td> 0.006</td> <td>   76.628</td> <td>  327.932</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P3_std</th>    <td>  120.4986</td> <td>   34.491</td> <td>    3.494</td> <td> 0.008</td> <td>   40.961</td> <td>  200.036</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.392</td> <th>  Durbin-Watson:     </th> <td>   1.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.822</td> <th>  Jarque-Bera (JB):  </th> <td>   0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.282</td> <th>  Prob(JB):          </th> <td>   0.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.625</td> <th>  Cond. No.          </th> <td>    350.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      F\\_std      & \\textbf{  R-squared:         } &     0.807   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.734   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     11.12   \\\\\n",
       "\\textbf{Date:}             & Sat, 07 Oct 2023 & \\textbf{  Prob (F-statistic):} &  0.00317    \\\\\n",
       "\\textbf{Time:}             &     15:22:49     & \\textbf{  Log-Likelihood:    } &   -7.1718   \\\\\n",
       "\\textbf{No. Observations:} &          12      & \\textbf{  AIC:               } &     22.34   \\\\\n",
       "\\textbf{Df Residuals:}     &           8      & \\textbf{  BIC:               } &     24.28   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &    1.735e-17  &        0.156     &  1.12e-16  &         1.000        &       -0.359    &        0.359     \\\\\n",
       "\\textbf{P1\\_std}   &       0.6913  &        0.289     &     2.390  &         0.044        &        0.024    &        1.358     \\\\\n",
       "\\textbf{P2\\_std}   &     202.2802  &       54.489     &     3.712  &         0.006        &       76.628    &      327.932     \\\\\n",
       "\\textbf{P3\\_std}   &     120.4986  &       34.491     &     3.494  &         0.008        &       40.961    &      200.036     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.392 & \\textbf{  Durbin-Watson:     } &    1.043  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.822 & \\textbf{  Jarque-Bera (JB):  } &    0.230  \\\\\n",
       "\\textbf{Skew:}          & -0.282 & \\textbf{  Prob(JB):          } &    0.891  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.625 & \\textbf{  Cond. No.          } &     350.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  F_std   R-squared:                       0.807\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     11.12\n",
       "Date:                Sat, 07 Oct 2023   Prob (F-statistic):            0.00317\n",
       "Time:                        15:22:49   Log-Likelihood:                -7.1718\n",
       "No. Observations:                  12   AIC:                             22.34\n",
       "Df Residuals:                       8   BIC:                             24.28\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   1.735e-17      0.156   1.12e-16      1.000      -0.359       0.359\n",
       "P1_std         0.6913      0.289      2.390      0.044       0.024       1.358\n",
       "P2_std       202.2802     54.489      3.712      0.006      76.628     327.932\n",
       "P3_std       120.4986     34.491      3.494      0.008      40.961     200.036\n",
       "==============================================================================\n",
       "Omnibus:                        0.392   Durbin-Watson:                   1.043\n",
       "Prob(Omnibus):                  0.822   Jarque-Bera (JB):                0.230\n",
       "Skew:                          -0.282   Prob(JB):                        0.891\n",
       "Kurtosis:                       2.625   Cond. No.                         350.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[:, 0 : p + 1]\n",
    "Y = data[:, -1]\n",
    "# 求均值\n",
    "X_mean = []\n",
    "for k in range(p + 1):\n",
    "    X_mean.append(np.mean(data[:, k]))  # 自变量 x 的均值\n",
    "Y_mean = np.mean(data[:, -1])  # 因变量 y 的均值\n",
    "\n",
    "# 标准化\n",
    "X_std = (X - X_mean) / np.std(X)\n",
    "Y_std = (Y - Y_mean) / np.std(Y)\n",
    "\n",
    "# Do the multiple linear regression\n",
    "df = pd.DataFrame(X_std, columns=['intercept_std', 'P1_std', 'P2_std', 'P3_std'])\n",
    "df['F_std'] = Y_std\n",
    "model_std = ols('F_std ~ P1_std + P2_std + P3_std', df).fit()\n",
    "beta_std = model_std.params\n",
    "print('参数估计值: \\n', round(beta_std, 4))\n",
    "Y_hat_std = model_std.fittedvalues\n",
    "model_std.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e94e3b6",
   "metadata": {},
   "source": [
    "在标准化的过程中，X没有指定axis=0。如果不指定 axis=0，np.std(X) 将计算整个矩阵 X 的标准差，得到的是一个标量值，而我们通常期望的是对每一列（每个自变量）分别计算标准差，以便进行标准化。\n",
    "\n",
    "通过指定 axis=0，我们告诉 NumPy 在每一列上计算标准差，而不是整个矩阵。这样，X_std 将包含每个自变量的标准化值，而不是整个矩阵的标准差。\n",
    "\n",
    "因此，指定 axis=0 是确保正确计算每个自变量的标准差，并进行正确的标准化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d3773",
   "metadata": {},
   "source": [
    "#### 2、矩阵乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ccfdb",
   "metadata": {},
   "source": [
    "由np.array()多维数组定义的矩阵，使用运算符“@”可以进行矩阵乘法。'*'运算符是将两个向量中每个元素进行相乘，是数乘运算，需要两个参与运算的矩阵维度相同。'np.dot()'和'@'运算符都可以起到矩阵乘法的作用，在处理连乘时‘@’相对方便。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed51c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
